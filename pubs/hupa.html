<html>
    <head>
        <title>Rishi Jha</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="../main.css">
        <link rel="stylesheet" href="../content.css">
        <link rel="shortcut icon" type="image/png" href="../im/favicon.png"/>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Abril+Fatface&family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
    </head>
    <body>
        <div class="outer">
            <main>
                <h1><a href="../index.html">Rishi D. Jha</a></h1>
                <div class="sidebar">
                    <a class="sidebar_content" href="../publications.html">publications</a>
                </div>
                <b class="line"></b>
                <div class="content">
                    <p class="ptitle">Hyper-Universal Policy Approximation: Learning to Generate Actions from a Single Image using Hypernets</p>
                    <p class="subtitle"><b>NeuroVision '22 @ CVPR</b> | Undergraduate | Center for Neurotechnology | June 2022</p>
                    <a class="links" href="https://arxiv.org/abs/2207.03593">[pdf]</a>
                    <p class="abstract">Inspired by Gibson's notion of object affordances in human vision, we ask the question: how can an agent learn to predict an entire action policy for a novel object or environment given only a single glimpse?
                        To tackle this problem, we introduce the concept of Universal Policy Functions (UPFs) which are state-to-action mappings that generalize not only to new goals but most importantly to novel, unseen environments.
                        Specifically, we consider the problem of efficiently learning such policies for agents with limited computational and communication capacity, constraints that are frequently encountered in edge devices.
                        We propose the Hyper-Universal Policy Approximator (HUPA), a hypernetwork-based model to generate small task- and environment-conditional policy networks from a single image, with good generalization properties.
                        Our results show that HUPAs significantly outperform an embedding-based alternative for generated policies that are size-constrained.
                        Although this work is restricted to a simple map-based navigation task, future work includes applying the principles behind HUPAs to learning more general affordances for objects and environments.
                    </p>
                </div>
            </main>        
        </div>
    </body>
</html>